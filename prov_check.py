import os
import numpy as np
import faiss
import json
from tqdm import tqdm

# ===============================
# ğŸ”‘ ConfiguraciÃ³
# ===============================
CORPUS_PATH = "../Miscerebot_backup/data/corpus_original.jsonl"
EMB_PATH = "../Miscerebot_backup/data/embeddings_G_pro_large.npy"
INDEX_PATH = "../Miscerebot_backup/data/faiss_index_G_pro_large.index"

# ===============================
# ğŸ§¾ Carrega els documents
# ===============================
with open(CORPUS_PATH, "r") as f:
    docs = [json.loads(line) for line in f if line.strip()]
print(f"âœ… Carregats {len(docs)} documents de {CORPUS_PATH}")

# ===============================
# ğŸ’¾ Carrega embeddings existents si hi ha
# ===============================
if os.path.exists(EMB_PATH):
    embeddings = np.load(EMB_PATH)
    print(f"ğŸ” Checkpoint trobat: {embeddings.shape[0]} vectors amb dimensiÃ³ {embeddings.shape[1]}")
else:
    raise ValueError("âŒ No hi ha embeddings; generaâ€™ls abans.")

# ===============================
# ğŸ”§ Comprova dimensiÃ³ embeddings
# ===============================
expected_dim = 3072  # nova dimensiÃ³ correcta pel model text-embedding-3-large
if embeddings.shape[1] != expected_dim:
    raise ValueError(f"âŒ DimensiÃ³ incorrecta: {embeddings.shape[1]}, esperada {expected_dim}")

# ===============================
# ğŸ§® Normalitza embeddings
# ===============================
embeddings_norm = embeddings / np.maximum(np.linalg.norm(embeddings, axis=1, keepdims=True), 1e-9)
print("âœ… Embeddings normalitzats")

# ===============================
# âš™ï¸ Crea Ã­ndex FAISS amb dimensiÃ³ correcta
# ===============================
index = faiss.IndexFlatIP(expected_dim)
index.add(embeddings_norm)
print(f"âœ… Ãndex FAISS creat amb {index.ntotal} vectors")

# ===============================
# ğŸ’¾ Desa Ã­ndex FAISS
# ===============================
faiss.write_index(index, INDEX_PATH)
print(f"âœ… FAISS index guardat a {INDEX_PATH}")

